{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'dic_moledo' from 'c:\\\\Users\\\\mathe\\\\OneDrive\\\\Documentos\\\\Códigos\\\\RECONHECIMENTO-DE-PADROES-COM-INTELIGENCIA-ARTIFICIAL-MICRODADOS-ENEM\\\\Moledo\\\\dic_moledo.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when, col\n",
    "from ydata_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dic_moledo\n",
    "from pyspark.sql.functions import col, create_map, lit\n",
    "from itertools import chain\n",
    "import importlib\n",
    "\n",
    "importlib.reload(dic_moledo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spark.driver.host': 'LAPTOP-615CB2PC', 'spark.driver.extraJavaOptions': '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false', 'spark.driver.memory': '4g', 'spark.executor.memory': '4g', 'spark.executor.id': 'driver', 'spark.app.id': 'local-1713222533032', 'spark.app.startTime': '1713222531521', 'spark.app.name': 'Minha Aplicação', 'spark.driver.port': '52522', 'spark.rdd.compress': 'True', 'spark.executor.extraJavaOptions': '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false', 'spark.serializer.objectStreamReset': '100', 'spark.driver.maxResultSize': '2g', 'spark.master': 'local[*]', 'spark.submit.pyFiles': '', 'spark.submit.deployMode': 'client', 'spark.app.submitTime': '1713222531195', 'spark.ui.showConsoleProgress': 'true', 'spark.executor.memoryOverhead': '1g'}\n"
     ]
    }
   ],
   "source": [
    "# Configura a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Minha Aplicação\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Agora você pode verificar todas as configurações atuais\n",
    "conf = spark.sparkContext.getConf()\n",
    "print({item[0]: item[1] for item in conf.getAll()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo um arquivo CSV\n",
    "df = spark.read.csv(\"MICRODADOS_ENEM_2022.csv\", header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------+-----------------+---------------+----+----+----+----+----+----+\n",
      "|TP_COR_RACA|TP_NACIONALIDADE|TP_ANO_CONCLUIU|TP_ESCOLA|CO_UF_PROVA|SG_UF_PROVA|TP_PRESENCA_CN|TP_PRESENCA_CH|TP_PRESENCA_LC|TP_PRESENCA_MT|NU_NOTA_CN|NU_NOTA_CH|NU_NOTA_LC|NU_NOTA_MT|TP_LINGUA|TP_STATUS_REDACAO|NU_NOTA_REDACAO|Q001|Q002|Q003|Q004|Q006|Q024|\n",
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------+-----------------+---------------+----+----+----+----+----+----+\n",
      "|          2|               1|              2|        1|         53|         DF|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   A|   A|   A|   B|   B|   A|\n",
      "|          1|               1|             16|        1|         53|         DF|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   D|   D|   E|   E|   Q|   E|\n",
      "|          2|               1|              2|        1|         29|         BA|             1|             1|             1|             1|     421.1|       546|     498.8|     565.3|        1|                1|            760|   E|   F|   A|   D|   B|   A|\n",
      "|          3|               1|              2|        1|         32|         ES|             1|             1|             1|             1|     490.7|     388.6|     357.8|       416|        1|                1|            320|   C|   A|   A|   B|   A|   B|\n",
      "|          3|               1|              1|        1|         15|         PA|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   D|   B|   A|   B|   B|   A|\n",
      "|          3|               1|              2|        1|         33|         RJ|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   E|   C|   B|   B|   C|   A|\n",
      "|          2|               1|              2|        1|         26|         PE|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   B|   B|   B|   B|   B|   A|\n",
      "|          2|               1|              0|        1|         33|         RJ|             1|             1|             1|             1|     398.1|     427.3|     400.2|     404.9|        1|                1|            440|   E|   E|   B|   B|   B|   A|\n",
      "|          3|               1|              0|        1|         29|         BA|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   A|   D|   A|   A|   B|   A|\n",
      "|          3|               1|              1|        1|         26|         PE|             1|             1|             1|             1|     467.5|       461|     466.7|     435.3|        1|                1|            360|   E|   E|   B|   B|   B|   A|\n",
      "|          3|               1|              2|        1|         25|         PB|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   E|   B|   A|   A|   A|   A|\n",
      "|          1|               1|              0|        3|         28|         SE|             1|             1|             1|             1|     458.7|     539.8|     488.2|     456.8|        1|                1|            940|   E|   E|   B|   A|   B|   A|\n",
      "|          2|               1|              1|        1|         29|         BA|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   D|   B|   F|   A|   B|   B|\n",
      "|          3|               1|              0|        1|         35|         SP|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   C|   E|   C|   D|   C|   A|\n",
      "|          2|               2|              3|        1|         51|         MT|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   E|   E|   B|   B|   C|   B|\n",
      "|          3|               1|              0|        2|         28|         SE|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        1|             NULL|           NULL|   B|   C|   B|   B|   B|   A|\n",
      "|          2|               1|              0|        1|         29|         BA|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   A|   D|   B|   B|   B|   A|\n",
      "|          3|               1|              0|        1|         35|         SP|             1|             1|             1|             1|     396.8|     528.7|     551.4|       536|        0|                1|            640|   G|   F|   F|   F|   B|   B|\n",
      "|          2|               1|              5|        1|         31|         MG|             1|             1|             1|             1|     481.4|     603.6|       589|       695|        1|                1|            860|   B|   F|   A|   D|   B|   A|\n",
      "|          1|               1|              0|        1|         33|         RJ|             0|             0|             0|             0|      NULL|      NULL|      NULL|      NULL|        0|             NULL|           NULL|   D|   B|   F|   D|   D|   A|\n",
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+----------+----------+----------+----------+---------+-----------------+---------------+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunas_descartadas = ['NU_INSCRICAO', 'NU_ANO', 'TP_ENSINO','CO_MUNICIPIO_ESC', 'NO_MUNICIPIO_ESC', 'CO_UF_ESC', 'SG_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', \n",
    "                       'TP_SIT_FUNC_ESC', 'CO_MUNICIPIO_PROVA', 'NO_MUNICIPIO_PROVA', 'CO_PROVA_CN', 'CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT','TX_RESPOSTAS_CN', 'TX_RESPOSTAS_CH', \n",
    "                       'TX_RESPOSTAS_LC', 'TX_RESPOSTAS_MT', 'TX_GABARITO_CN', 'TX_GABARITO_CH', 'TX_GABARITO_LC', 'TX_GABARITO_MT', 'NU_NOTA_COMP1', \n",
    "                       'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5','TP_SEXO','TP_ESTADO_CIVIL','Q011','Q005','Q007','Q008','Q009','Q010','Q012','Q013','Q015',\n",
    "                       'Q016','Q017','Q018','Q019','Q020','Q021','Q023','Q014','Q022','Q025','TP_ST_CONCLUSAO','TP_FAIXA_ETARIA','IN_TREINEIRO']\n",
    "\n",
    "# Descartando colunas\n",
    "df = df.drop(*colunas_descartadas)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2122885"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descartando linhas que contem valores diferentes de 1 em TP_PRESENCA_CN\n",
    "df = df.filter(df.TP_PRESENCA_CN == 1)\n",
    "df = df.filter(df.TP_PRESENCA_CH == 1)\n",
    "df = df.filter(df.TP_PRESENCA_LC == 1)\n",
    "df = df.filter(df.TP_PRESENCA_MT == 1)\n",
    "\n",
    "df.count()\n",
    "\n",
    "# Descartando colunas que contem valores H na coluna Q001 e Q002\n",
    "df = df.filter(df.Q001 != 'H')\n",
    "df = df.filter(df.Q002 != 'H')\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+---------+-----------------+---------------+----+----+----+----+----+----+------------------+\n",
      "|TP_COR_RACA|TP_NACIONALIDADE|TP_ANO_CONCLUIU|TP_ESCOLA|CO_UF_PROVA|SG_UF_PROVA|TP_PRESENCA_CN|TP_PRESENCA_CH|TP_PRESENCA_LC|TP_PRESENCA_MT|TP_LINGUA|TP_STATUS_REDACAO|NU_NOTA_REDACAO|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|\n",
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+---------+-----------------+---------------+----+----+----+----+----+----+------------------+\n",
      "|          2|               1|              2|        1|         29|         BA|             1|             1|             1|             1|        1|                1|            760|   E|   F|   A|   D|   B|   A|            558.24|\n",
      "|          3|               1|              2|        1|         32|         ES|             1|             1|             1|             1|        1|                1|            320|   C|   A|   A|   B|   A|   B|            394.62|\n",
      "|          2|               1|              0|        1|         33|         RJ|             1|             1|             1|             1|        1|                1|            440|   E|   E|   B|   B|   B|   A|             414.1|\n",
      "|          3|               1|              1|        1|         26|         PE|             1|             1|             1|             1|        1|                1|            360|   E|   E|   B|   B|   B|   A|             438.1|\n",
      "|          1|               1|              0|        3|         28|         SE|             1|             1|             1|             1|        1|                1|            940|   E|   E|   B|   A|   B|   A|             576.7|\n",
      "|          3|               1|              0|        1|         35|         SP|             1|             1|             1|             1|        0|                1|            640|   G|   F|   F|   F|   B|   B|            530.58|\n",
      "|          2|               1|              5|        1|         31|         MG|             1|             1|             1|             1|        1|                1|            860|   B|   F|   A|   D|   B|   A|             645.8|\n",
      "|          1|               1|              0|        1|         33|         RJ|             1|             1|             1|             1|        1|                1|            640|   B|   D|   D|   B|   B|   B|             500.4|\n",
      "|          3|               1|              1|        1|         23|         CE|             1|             1|             1|             1|        1|                1|            760|   E|   E|   B|   B|   E|   A|            605.58|\n",
      "|          3|               1|              4|        1|         29|         BA|             1|             1|             1|             1|        0|                1|            520|   C|   C|   A|   A|   C|   A|445.56000000000006|\n",
      "|          2|               1|              3|        1|         29|         BA|             1|             1|             1|             1|        0|                1|            640|   E|   E|   D|   B|   B|   B| 548.5400000000001|\n",
      "|          3|               1|              1|        1|         13|         AM|             1|             1|             1|             1|        1|                1|            640|   E|   E|   B|   D|   G|   C|            630.62|\n",
      "|          1|               1|              0|        1|         43|         RS|             1|             1|             1|             1|        0|                1|            360|   A|   F|   F|   E|   B|   A|            385.88|\n",
      "|          1|               1|              7|        1|         43|         RS|             1|             1|             1|             1|        0|                1|            760|   E|   E|   B|   B|   E|   B|            562.68|\n",
      "|          3|               1|              0|        1|         21|         MA|             1|             1|             1|             1|        0|                1|            540|   B|   D|   A|   A|   B|   A|             458.4|\n",
      "|          3|               1|             16|        1|         13|         AM|             1|             1|             1|             1|        0|                1|            360|   E|   E|   D|   B|   D|   B|493.53999999999996|\n",
      "|          3|               1|             13|        1|         26|         PE|             1|             1|             1|             1|        1|                1|            420|   B|   E|   C|   B|   D|   A|            415.84|\n",
      "|          1|               1|              1|        1|         35|         SP|             1|             1|             1|             1|        1|                1|            460|   C|   E|   A|   B|   C|   B|             501.5|\n",
      "|          3|               1|              0|        2|         23|         CE|             1|             1|             1|             1|        1|                1|            560|   C|   D|   C|   B|   B|   A|471.94000000000005|\n",
      "|          3|               1|              1|        1|         15|         PA|             1|             1|             1|             1|        1|                1|            360|   E|   E|   C|   B|   C|   A|            406.86|\n",
      "+-----------+----------------+---------------+---------+-----------+-----------+--------------+--------------+--------------+--------------+---------+-----------------+---------------+----+----+----+----+----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando a coluna media e descartando as colunas de notas\n",
    "df = df.withColumn('NU_NOTA_MEDIA', (col('NU_NOTA_CN') + col('NU_NOTA_CH') + col('NU_NOTA_LC') + col('NU_NOTA_MT') + col('NU_NOTA_REDACAO'))/5)\n",
    "df = df.drop('NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_MT')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_descartadas = ['TP_PRESENCA_CN','TP_PRESENCA_CH','TP_PRESENCA_LC','TP_PRESENCA_MT','TP_STATUS_REDACAO','SG_UF_PROVA','NU_NOTA_REDACAO','TP_ANO_CONCLUIU','TP_NACIONALIDADE']\n",
    "\n",
    "# Descartando colunas\n",
    "df = df.drop(*colunas_descartadas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17}\n"
     ]
    }
   ],
   "source": [
    "print(dic_moledo.q006_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\column.py:460: FutureWarning: A column as 'key' in getItem is deprecated as of Spark 3.0, and will not be supported in the future release. Use `column[key]` or `column.key` syntax instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Colunas Q001 ate Q025\n",
    "colunas = ['Q001','Q002','Q003','Q004','Q006','Q024']\n",
    "\n",
    "\n",
    "for coluna in colunas:\n",
    "    # Pegando os valores correspondentes a cada letra no dicionario dic\n",
    "    nome_dict = coluna.lower() + '_dict'  # Constrói o nome do dicionário\n",
    "    if hasattr(dic_moledo, nome_dict):  # Verifica se o dicionário existe no módulo dicionario\n",
    "        mapeamento = getattr(dic_moledo, nome_dict)  # Obtém o dicionário\n",
    "        mapeamento_expr = create_map([lit(x) for x in chain(*mapeamento.items())])\n",
    "        df = df.withColumn(coluna, mapeamento_expr.getItem(col(coluna)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "|TP_COR_RACA|TP_ESCOLA|CO_UF_PROVA|TP_LINGUA|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "|          2|        1|         29|        1|   5|   6|   1|   4|   2|   1|            558.24|\n",
      "|          3|        1|         32|        1|   3|   1|   1|   2|   1|   2|            394.62|\n",
      "|          2|        1|         33|        1|   5|   5|   2|   2|   2|   1|             414.1|\n",
      "|          3|        1|         26|        1|   5|   5|   2|   2|   2|   1|             438.1|\n",
      "|          1|        3|         28|        1|   5|   5|   2|   1|   2|   1|             576.7|\n",
      "|          3|        1|         35|        0|   7|   6|   6|   6|   2|   2|            530.58|\n",
      "|          2|        1|         31|        1|   2|   6|   1|   4|   2|   1|             645.8|\n",
      "|          1|        1|         33|        1|   2|   4|   4|   2|   2|   2|             500.4|\n",
      "|          3|        1|         23|        1|   5|   5|   2|   2|   5|   1|            605.58|\n",
      "|          3|        1|         29|        0|   3|   3|   1|   1|   3|   1|445.56000000000006|\n",
      "|          2|        1|         29|        0|   5|   5|   4|   2|   2|   2| 548.5400000000001|\n",
      "|          3|        1|         13|        1|   5|   5|   2|   4|   7|   3|            630.62|\n",
      "|          1|        1|         43|        0|   1|   6|   6|   5|   2|   1|            385.88|\n",
      "|          1|        1|         43|        0|   5|   5|   2|   2|   5|   2|            562.68|\n",
      "|          3|        1|         21|        0|   2|   4|   1|   1|   2|   1|             458.4|\n",
      "|          3|        1|         13|        0|   5|   5|   4|   2|   4|   2|493.53999999999996|\n",
      "|          3|        1|         26|        1|   2|   5|   3|   2|   4|   1|            415.84|\n",
      "|          1|        1|         35|        1|   3|   5|   1|   2|   3|   2|             501.5|\n",
      "|          3|        2|         23|        1|   3|   4|   3|   2|   2|   1|471.94000000000005|\n",
      "|          3|        1|         15|        1|   5|   5|   3|   2|   3|   1|            406.86|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "|TP_COR_RACA|TP_ESCOLA|CO_UF_PROVA|TP_LINGUA|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "|          2|        1|          4|        1|   5|   6|   1|   4|   2|   1|            558.24|\n",
      "|          3|        1|          1|        1|   3|   1|   1|   2|   1|   2|            394.62|\n",
      "|          2|        1|          1|        1|   5|   5|   2|   2|   2|   1|             414.1|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   2|   1|             438.1|\n",
      "|          1|        3|          4|        1|   5|   5|   2|   1|   2|   1|             576.7|\n",
      "|          3|        1|          1|        0|   7|   6|   6|   6|   2|   2|            530.58|\n",
      "|          2|        1|          1|        1|   2|   6|   1|   4|   2|   1|             645.8|\n",
      "|          1|        1|          1|        1|   2|   4|   4|   2|   2|   2|             500.4|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   5|   1|            605.58|\n",
      "|          3|        1|          4|        0|   3|   3|   1|   1|   3|   1|445.56000000000006|\n",
      "|          2|        1|          4|        0|   5|   5|   4|   2|   2|   2| 548.5400000000001|\n",
      "|          3|        1|          5|        1|   5|   5|   2|   4|   7|   3|            630.62|\n",
      "|          1|        1|          2|        0|   1|   6|   6|   5|   2|   1|            385.88|\n",
      "|          1|        1|          2|        0|   5|   5|   2|   2|   5|   2|            562.68|\n",
      "|          3|        1|          4|        0|   2|   4|   1|   1|   2|   1|             458.4|\n",
      "|          3|        1|          5|        0|   5|   5|   4|   2|   4|   2|493.53999999999996|\n",
      "|          3|        1|          4|        1|   2|   5|   3|   2|   4|   1|            415.84|\n",
      "|          1|        1|          1|        1|   3|   5|   1|   2|   3|   2|             501.5|\n",
      "|          3|        2|          4|        1|   3|   4|   3|   2|   2|   1|471.94000000000005|\n",
      "|          3|        1|          5|        1|   5|   5|   3|   2|   3|   1|            406.86|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituindo valores da CO_UF_PROVA para valores de regiao\n",
    "# Regiao Suldeste = 1\n",
    "# Regiao Sul = 2\n",
    "# Regiao Centro-Oeste = 3\n",
    "# Regiao Nordeste = 4\n",
    "# Regiao Norte = 5\n",
    "df = df.withColumn(\"CO_UF_PROVA\", \n",
    "    when(col(\"CO_UF_PROVA\").isin(['11', '12', '13', '14', '15', '16', '17']), 5)\n",
    "    .when(col(\"CO_UF_PROVA\").isin(['21', '22', '23', '24', '25', '26', '27', '28', '29', '30']), 4)\n",
    "    .when(col(\"CO_UF_PROVA\").isin(['50', '51', '52', '53']), 3)\n",
    "    .when(col(\"CO_UF_PROVA\").isin(['41', '42', '43']), 2)\n",
    "    .when(col(\"CO_UF_PROVA\").isin(['31', '32', '33', '35']), 1)\n",
    "    # Se nenhum dos when se aplicar, mantém o valor original da coluna 'CO_UF_PROVA'\n",
    "    .otherwise(col(\"CO_UF_PROVA\"))\n",
    ")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, TP_COR_RACA: string, TP_ESCOLA: string, CO_UF_PROVA: string, TP_LINGUA: string, Q001: string, Q002: string, Q003: string, Q004: string, Q006: string, Q024: string, NU_NOTA_MEDIA: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "df = df.withColumn(\"CO_UF_PROVA\", df[\"CO_UF_PROVA\"].cast(\"int\"))\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterando o tipo de dado de string para int \n",
    "df = df.withColumn(\"TP_COR_RACA\", df[\"TP_COR_RACA\"].cast(\"int\"))\n",
    "df = df.withColumn(\"TP_ESCOLA\", df[\"TP_ESCOLA\"].cast(\"int\"))\n",
    "df = df.withColumn(\"TP_LINGUA\", df[\"TP_LINGUA\"].cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:111: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 4.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"c:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m spark\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.execution.arrow.pyspark.enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Convert the Spark DataFrame back to a pandas DataFrame using Arrow\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result_pdf \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m result_pdf\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:202\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    204\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[0;32m    205\u001b[0m         rows, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows)), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1261\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \n\u001b[0;32m   1243\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[1;32m-> 1261\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# Convert the Spark DataFrame back to a pandas DataFrame using Arrow\n",
    "result_pdf = df.select(\"*\").toPandas()\n",
    "result_pdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'result_pdf = pd.get_dummies(result_pdf)\\nresult_pdf.head()'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''result_pdf = pd.get_dummies(result_pdf)\n",
    "result_pdf.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'profile = ProfileReport(result_pdf, title=\"Pandas Profiling Report\")\\nprofile.to_file(\"output_q006_reload.html\")'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''profile = ProfileReport(result_pdf, title=\"Pandas Profiling Report\")\n",
    "profile.to_file(\"output_q006_reload.html\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+\n",
      "|TP_COR_RACA|TP_ESCOLA|CO_UF_PROVA|TP_LINGUA|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|CLASSE_MEDIAS|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+\n",
      "|          2|        1|          4|        1|   5|   6|   1|   4|   2|   1|            558.24|        médio|\n",
      "|          3|        1|          1|        1|   3|   1|   1|   2|   1|   2|            394.62|        baixo|\n",
      "|          2|        1|          1|        1|   5|   5|   2|   2|   2|   1|             414.1|        baixo|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   2|   1|             438.1|        baixo|\n",
      "|          1|        3|          4|        1|   5|   5|   2|   1|   2|   1|             576.7|        médio|\n",
      "|          3|        1|          1|        0|   7|   6|   6|   6|   2|   2|            530.58|        médio|\n",
      "|          2|        1|          1|        1|   2|   6|   1|   4|   2|   1|             645.8|         alto|\n",
      "|          1|        1|          1|        1|   2|   4|   4|   2|   2|   2|             500.4|        baixo|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   5|   1|            605.58|         alto|\n",
      "|          3|        1|          4|        0|   3|   3|   1|   1|   3|   1|445.56000000000006|        baixo|\n",
      "|          2|        1|          4|        0|   5|   5|   4|   2|   2|   2| 548.5400000000001|        médio|\n",
      "|          3|        1|          5|        1|   5|   5|   2|   4|   7|   3|            630.62|         alto|\n",
      "|          1|        1|          2|        0|   1|   6|   6|   5|   2|   1|            385.88|        baixo|\n",
      "|          1|        1|          2|        0|   5|   5|   2|   2|   5|   2|            562.68|        médio|\n",
      "|          3|        1|          4|        0|   2|   4|   1|   1|   2|   1|             458.4|        baixo|\n",
      "|          3|        1|          5|        0|   5|   5|   4|   2|   4|   2|493.53999999999996|        baixo|\n",
      "|          3|        1|          4|        1|   2|   5|   3|   2|   4|   1|            415.84|        baixo|\n",
      "|          1|        1|          1|        1|   3|   5|   1|   2|   3|   2|             501.5|        baixo|\n",
      "|          3|        2|          4|        1|   3|   4|   3|   2|   2|   1|471.94000000000005|        baixo|\n",
      "|          3|        1|          5|        1|   5|   5|   3|   2|   3|   1|            406.86|        baixo|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_teste = df\n",
    "\n",
    "# Calcula os quantis aproximados para a coluna 'MEDIAS'\n",
    "limite_baixo = df_teste.stat.approxQuantile('NU_NOTA_MEDIA', [0.33], 0.01)[0]\n",
    "limite_alto = df_teste.stat.approxQuantile('NU_NOTA_MEDIA', [0.66], 0.01)[0]\n",
    "\n",
    "# Classifica cada linha em 'baixo', 'médio', 'alto' com base nos quantis calculados\n",
    "df_teste = df.withColumn(\n",
    "    'CLASSE_MEDIAS',\n",
    "    when(col('NU_NOTA_MEDIA') <= limite_baixo, 'baixo')\n",
    "    .when(col('NU_NOTA_MEDIA') <= limite_alto, 'médio')\n",
    "    .otherwise('alto')\n",
    ")\n",
    "\n",
    "# Mostra o DataFrame com a nova coluna de classificação\n",
    "df_teste.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+\n",
      "|TP_COR_RACA|TP_ESCOLA|CO_UF_PROVA|TP_LINGUA|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|CLASSE_MEDIAS|            features|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+\n",
      "|          2|        1|          4|        1|   5|   6|   1|   4|   2|   1|            558.24|        médio|[2.0,1.0,4.0,1.0,...|\n",
      "|          3|        1|          1|        1|   3|   1|   1|   2|   1|   2|            394.62|        baixo|[3.0,1.0,1.0,1.0,...|\n",
      "|          2|        1|          1|        1|   5|   5|   2|   2|   2|   1|             414.1|        baixo|[2.0,1.0,1.0,1.0,...|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   2|   1|             438.1|        baixo|[3.0,1.0,4.0,1.0,...|\n",
      "|          1|        3|          4|        1|   5|   5|   2|   1|   2|   1|             576.7|        médio|[1.0,3.0,4.0,1.0,...|\n",
      "|          3|        1|          1|        0|   7|   6|   6|   6|   2|   2|            530.58|        médio|[3.0,1.0,1.0,0.0,...|\n",
      "|          2|        1|          1|        1|   2|   6|   1|   4|   2|   1|             645.8|         alto|[2.0,1.0,1.0,1.0,...|\n",
      "|          1|        1|          1|        1|   2|   4|   4|   2|   2|   2|             500.4|        baixo|[1.0,1.0,1.0,1.0,...|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   5|   1|            605.58|         alto|[3.0,1.0,4.0,1.0,...|\n",
      "|          3|        1|          4|        0|   3|   3|   1|   1|   3|   1|445.56000000000006|        baixo|[3.0,1.0,4.0,0.0,...|\n",
      "|          2|        1|          4|        0|   5|   5|   4|   2|   2|   2| 548.5400000000001|        médio|[2.0,1.0,4.0,0.0,...|\n",
      "|          3|        1|          5|        1|   5|   5|   2|   4|   7|   3|            630.62|         alto|[3.0,1.0,5.0,1.0,...|\n",
      "|          1|        1|          2|        0|   1|   6|   6|   5|   2|   1|            385.88|        baixo|[1.0,1.0,2.0,0.0,...|\n",
      "|          1|        1|          2|        0|   5|   5|   2|   2|   5|   2|            562.68|        médio|[1.0,1.0,2.0,0.0,...|\n",
      "|          3|        1|          4|        0|   2|   4|   1|   1|   2|   1|             458.4|        baixo|[3.0,1.0,4.0,0.0,...|\n",
      "|          3|        1|          5|        0|   5|   5|   4|   2|   4|   2|493.53999999999996|        baixo|[3.0,1.0,5.0,0.0,...|\n",
      "|          3|        1|          4|        1|   2|   5|   3|   2|   4|   1|            415.84|        baixo|[3.0,1.0,4.0,1.0,...|\n",
      "|          1|        1|          1|        1|   3|   5|   1|   2|   3|   2|             501.5|        baixo|[1.0,1.0,1.0,1.0,...|\n",
      "|          3|        2|          4|        1|   3|   4|   3|   2|   2|   1|471.94000000000005|        baixo|[3.0,2.0,4.0,1.0,...|\n",
      "|          3|        1|          5|        1|   5|   5|   3|   2|   3|   1|            406.86|        baixo|[3.0,1.0,5.0,1.0,...|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Inicia uma sessão Spark\n",
    "spark = SparkSession.builder.appName(\"RandomForestExample\").getOrCreate()\n",
    "\n",
    "# Lista de colunas para usar como features\n",
    "feature_cols = ['TP_COR_RACA', 'TP_ESCOLA', 'CO_UF_PROVA','TP_LINGUA', 'Q001', 'Q002', 'Q003', 'Q004', 'Q006', 'Q024']\n",
    "\n",
    "# Assembler para transformar as colunas de feature em um vetor único\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "df_teste = assembler.transform(df_teste)\n",
    "df_teste.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+----------+\n",
      "|TP_COR_RACA|TP_ESCOLA|CO_UF_PROVA|TP_LINGUA|Q001|Q002|Q003|Q004|Q006|Q024|     NU_NOTA_MEDIA|CLASSE_MEDIAS|            features|labelIndex|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+----------+\n",
      "|          2|        1|          4|        1|   5|   6|   1|   4|   2|   1|            558.24|        médio|[2.0,1.0,4.0,1.0,...|       1.0|\n",
      "|          3|        1|          1|        1|   3|   1|   1|   2|   1|   2|            394.62|        baixo|[3.0,1.0,1.0,1.0,...|       2.0|\n",
      "|          2|        1|          1|        1|   5|   5|   2|   2|   2|   1|             414.1|        baixo|[2.0,1.0,1.0,1.0,...|       2.0|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   2|   1|             438.1|        baixo|[3.0,1.0,4.0,1.0,...|       2.0|\n",
      "|          1|        3|          4|        1|   5|   5|   2|   1|   2|   1|             576.7|        médio|[1.0,3.0,4.0,1.0,...|       1.0|\n",
      "|          3|        1|          1|        0|   7|   6|   6|   6|   2|   2|            530.58|        médio|[3.0,1.0,1.0,0.0,...|       1.0|\n",
      "|          2|        1|          1|        1|   2|   6|   1|   4|   2|   1|             645.8|         alto|[2.0,1.0,1.0,1.0,...|       0.0|\n",
      "|          1|        1|          1|        1|   2|   4|   4|   2|   2|   2|             500.4|        baixo|[1.0,1.0,1.0,1.0,...|       2.0|\n",
      "|          3|        1|          4|        1|   5|   5|   2|   2|   5|   1|            605.58|         alto|[3.0,1.0,4.0,1.0,...|       0.0|\n",
      "|          3|        1|          4|        0|   3|   3|   1|   1|   3|   1|445.56000000000006|        baixo|[3.0,1.0,4.0,0.0,...|       2.0|\n",
      "|          2|        1|          4|        0|   5|   5|   4|   2|   2|   2| 548.5400000000001|        médio|[2.0,1.0,4.0,0.0,...|       1.0|\n",
      "|          3|        1|          5|        1|   5|   5|   2|   4|   7|   3|            630.62|         alto|[3.0,1.0,5.0,1.0,...|       0.0|\n",
      "|          1|        1|          2|        0|   1|   6|   6|   5|   2|   1|            385.88|        baixo|[1.0,1.0,2.0,0.0,...|       2.0|\n",
      "|          1|        1|          2|        0|   5|   5|   2|   2|   5|   2|            562.68|        médio|[1.0,1.0,2.0,0.0,...|       1.0|\n",
      "|          3|        1|          4|        0|   2|   4|   1|   1|   2|   1|             458.4|        baixo|[3.0,1.0,4.0,0.0,...|       2.0|\n",
      "|          3|        1|          5|        0|   5|   5|   4|   2|   4|   2|493.53999999999996|        baixo|[3.0,1.0,5.0,0.0,...|       2.0|\n",
      "|          3|        1|          4|        1|   2|   5|   3|   2|   4|   1|            415.84|        baixo|[3.0,1.0,4.0,1.0,...|       2.0|\n",
      "|          1|        1|          1|        1|   3|   5|   1|   2|   3|   2|             501.5|        baixo|[1.0,1.0,1.0,1.0,...|       2.0|\n",
      "|          3|        2|          4|        1|   3|   4|   3|   2|   2|   1|471.94000000000005|        baixo|[3.0,2.0,4.0,1.0,...|       2.0|\n",
      "|          3|        1|          5|        1|   5|   5|   3|   2|   3|   1|            406.86|        baixo|[3.0,1.0,5.0,1.0,...|       2.0|\n",
      "+-----------+---------+-----------+---------+----+----+----+----+----+----+------------------+-------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Indexação de strings para a coluna alvo\n",
    "label_stringIdx = StringIndexer(inputCol='CLASSE_MEDIAS', outputCol='labelIndex')\n",
    "df_teste = label_stringIdx.fit(df_teste).transform(df_teste)\n",
    "df_teste.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1485338\n",
      "Test Dataset Count: 637547\n"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap: Whether bootstrap samples are used when building trees. (default: True)\n",
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: auto)\n",
      "featuresCol: features column name. (default: features, current: features)\n",
      "impurity: Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini (default: gini)\n",
      "labelCol: label column name. (default: label, current: labelIndex)\n",
      "leafCol: Leaf indices column name. Predicted leaf index of each instance in each tree by preorder. (default: )\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30]. (default: 5)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "minWeightFractionPerNode: Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5). (default: 0.0)\n",
      "numTrees: Number of trees to train (>= 1). (default: 20)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "seed: random seed. (default: 106576186859740348)\n",
      "subsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "features does not exist. Available: TP_COR_RACA, TP_ESCOLA, CO_UF_PROVA, TP_LINGUA, Q001, Q002, Q003, Q004, Q006, Q024, NU_NOTA_MEDIA",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m,labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabelIndex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(rf\u001b[38;5;241m.\u001b[39mexplainParams())\n\u001b[1;32m----> 4\u001b[0m rfModel \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m rfModel\u001b[38;5;241m.\u001b[39mtransform(test)\n\u001b[0;32m      6\u001b[0m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP_COR_RACA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP_ESCOLA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCO_UF_PROVA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTP_LINGUA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ001\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ002\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ003\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ004\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ006\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ024\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\mathe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: features does not exist. Available: TP_COR_RACA, TP_ESCOLA, CO_UF_PROVA, TP_LINGUA, Q001, Q002, Q003, Q004, Q006, Q024, NU_NOTA_MEDIA"
     ]
    }
   ],
   "source": [
    "# Criação do modelo RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol='features',labelCol='labelIndex')\n",
    "print(rf.explainParams())\n",
    "rfModel = rf.fit(train)\n",
    "predictions = rfModel.transform(test)\n",
    "predictions.select('TP_COR_RACA', 'TP_ESCOLA', 'CO_UF_PROVA', 'TP_LINGUA', 'Q001',\n",
    "                    'Q002', 'Q003', 'Q004', 'Q006', 'Q024', 'prediction', 'probability').show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NU_NOTA_MEDIA'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NU_NOTA_MEDIA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Cálculo da média e classificação\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m result_pdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLASSE_MEDIAS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcut(\u001b[43mresult_pdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNU_NOTA_MEDIA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m700\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)], labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaixo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmédio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malto\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m result_pdf\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNU_NOTA_MEDIA\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Continue com o processamento após essa correção...\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NU_NOTA_MEDIA'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cálculo da média e classificação\n",
    "result_pdf['CLASSE_MEDIAS'] = pd.cut(result_pdf['NU_NOTA_MEDIA'], bins=[0, 500, 700, float('inf')], labels=['baixo', 'médio', 'alto'])\n",
    "result_pdf.drop('NU_NOTA_MEDIA', axis=1, inplace=True)\n",
    "# Continue com o processamento após essa correção...\n",
    "print(result_pdf.head())\n",
    "result_pdf = result_pdf.dropna()\n",
    "print(result_pdf['CLASSE_MEDIAS'].value_counts())\n",
    "# Preparação dos dados para modelagem\n",
    "X = result_pdf.drop('CLASSE_MEDIAS', axis=1)\n",
    "y = result_pdf['CLASSE_MEDIAS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Avaliação do\n",
    "# Modelagem usando Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Avaliação do\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação do modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliação do\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_63024\\3856552612.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualização da matriz de confusão\n",
    "fig, ax = plt.subplots(figsize=(8, 8))  # Ajuste o tamanho conforme necessário\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.xlabel('Previsões')\n",
    "plt.ylabel('Verdadeiros')\n",
    "\n",
    "# Salve a imagem como png\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
